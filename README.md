Uncertainty-Guided Spatiotemporal Consistency Fusion Network for Infrared-Visible Video Fusion under Extremely Low-Light Conditions

## ğŸ“ Project & Resources

| Resource | Status | Link |
|--------|--------|------|
| ğŸŒ Project Page | **LIVE!** | [Click Here for Visualizations](https://zhaocheng1.github.io/ELVID/) |
| ğŸ“„ Paper | Under Review |Coming Soon |
 ğŸ“Š Datasets | **Upon Acceptance** | See Dataset Release Status â†“ |
| ğŸ’» Code | Coming Soon | See Code and Model Release Status â†“ |

## ğŸ“Š Dataset Release Status
![Dataset Release](https://img.shields.io/badge/Dataset%20Release-Upon%20Acceptance-orange)

We are committed to open and reproducible research.

The ELVID dataset, which includes aligned infraredâ€“visible video pairs, is currently withheld to preserve the integrity of the peer-review process.

We guarantee that the complete dataset will be made publicly available immediately upon manuscript acceptance.


## ğŸ”‘ Code and Model Release Status
![Code Release](https://img.shields.io/badge/Code%20Release-Upon%20Acceptance-orange)

We are committed to full reproducibility and open science.

The source code, trained models, and detailed setup instructions are currently withheld to preserve the integrity of the academic peer-review process.

We guarantee that the complete repository contents (including training scripts and pretrained checkpoints) will be made publicly available immediately upon manuscript acceptance.

## ğŸ“‘ Citation

If you find our work useful for your research, please consider citing our paper:

```bibtex
@article{Zhao2025SCFNet,
  title   = {Uncertainty-Guided Spatiotemporal Consistency Fusion Network for Infrared--Visible Video Fusion under Extremely Low-Light Conditions},
  author  = {Zhao, Cheng and Song, Tianyun and Wu, Zhiliang and Wang, Tianfu and Gabbouj, Moncef and Yue, Guanghui and Lei, Baiying and Zhou, Wei},
  journal = {Under Review},
  year    = {2025}
}
